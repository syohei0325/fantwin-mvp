// DMè‡ªå‹•ç”Ÿæˆãƒ©ã‚¤ãƒ–ãƒ©ãƒª for FanTwin Chrome Extension
// @mvp_checklist.md: Hello-World DM â†’ 120æ–‡å­—ä»¥ä¸Š â†’ é€ä¿¡ãƒœã‚¿ãƒ³1ã‚¯ãƒªãƒƒã‚¯
// @mvp_checklist.md p50 Latency < 0.5s: è¿”ä¿¡ç”Ÿæˆé€Ÿåº¦æœ€å„ªå…ˆ
// @implementation_plan.md W1: p50 Latency < 0.6s ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°

import OpenAI from 'openai';

export interface DMGenerationOptions {
  fanName?: string;
  creatorName?: string;
  platform: 'twitter' | 'instagram' | 'tiktok';
  tone: 'friendly' | 'professional' | 'casual' | 'enthusiastic';
  language: 'ja' | 'en' | 'auto';
  minLength: number;
  maxLength: number;
}

export interface DMResult {
  message: string;
  length: number;
  tone: string;
  estimatedSentiment: 'positive' | 'neutral' | 'professional';
  generatedAt: string;
}

interface DMRequest {
  targetUser: string;
  context?: string;
  tone?: 'friendly' | 'professional' | 'casual';
  language?: 'ja' | 'en';
  maxLength?: number;
}

interface DMResponse {
  message: string;
  length: number;
  sentiment: 'positive' | 'neutral' | 'professional';
  generationTimeMs: number;
  cached: boolean;
  model: string;
}

interface LatencyMetrics {
  p50: number;
  p95: number;
  p99: number;
  average: number;
  count: number;
  lastUpdated: number;
}

// OpenAI ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚¯ãƒ©ã‚¹
export class DMGenerator {
  private openai: OpenAI | null = null;
  private modelConfig: {
    model: string;
    temperature: number;
    maxTokens: number;
  };
  private cache = new Map<string, { response: DMResponse; timestamp: number }>();
  private readonly CACHE_TTL = 5 * 60 * 1000; // 5åˆ†ã‚­ãƒ£ãƒƒã‚·ãƒ¥
  private readonly TARGET_LATENCY = 500; // 0.5ç§’ç›®æ¨™
  private latencyHistory: number[] = [];
  private readonly MAX_HISTORY = 1000;

  constructor(apiKey?: string) {
    // @mvp_checklist.md: Cost Guardrail - min(MRRÃ—0.25, USD 150)å¯¾å¿œ
    this.openai = new OpenAI({
      apiKey: apiKey || process.env.OPENAI_API_KEY || 'placeholder-key',
      dangerouslyAllowBrowser: true // Chrome extensionç”¨
    });

    // Week-1ã¯GPT-4o-miniä½¿ç”¨ï¼ˆFree ãƒ—ãƒ©ãƒ³ç”¨ï¼‰
    this.modelConfig = {
      model: 'gpt-4o-mini',
      temperature: 0.7,
      maxTokens: 150
    };
  }

  // Hello-World DMç”Ÿæˆï¼ˆD1 Activationç”¨ï¼‰
  async generateHelloWorldDM(options: Partial<DMGenerationOptions> = {}): Promise<DMResult> {
    const config: DMGenerationOptions = {
      platform: 'twitter',
      tone: 'friendly',
      language: 'ja',
      minLength: 120,
      maxLength: 280,
      creatorName: 'ã‚ãªãŸ',
      ...options
    };

    try {
      const prompt = this.buildHelloWorldPrompt(config);
      console.log('ğŸ¤– Generating Hello-World DM with OpenAI...');

      const response = await this.openai.chat.completions.create({
        model: this.modelConfig.model,
        messages: [
          {
            role: 'system',
            content: this.getSystemPrompt(config)
          },
          {
            role: 'user',
            content: prompt
          }
        ],
        temperature: this.modelConfig.temperature,
        max_tokens: this.modelConfig.maxTokens
      });

      const generatedMessage = response.choices[0]?.message?.content?.trim() || '';
      
      if (generatedMessage.length < config.minLength) {
        console.warn(`âš ï¸ Generated message too short: ${generatedMessage.length} chars`);
        return this.generateFallbackDM(config);
      }

      const result: DMResult = {
        message: generatedMessage,
        length: generatedMessage.length,
        tone: config.tone,
        estimatedSentiment: this.analyzeSentiment(generatedMessage),
        generatedAt: new Date().toISOString()
      };

      console.log('âœ… Hello-World DM generated successfully:', result.length, 'chars');
      return result;

    } catch (error) {
      console.error('âŒ DM generation failed:', error);
      return this.generateFallbackDM(config);
    }
  }

  // ãƒ‘ãƒ¼ã‚½ãƒŠãƒ©ã‚¤ã‚ºDMç”Ÿæˆï¼ˆTrial/Pro ãƒ—ãƒ©ãƒ³ç”¨ï¼‰
  async generatePersonalizedDM(
    fanContext: string,
    options: Partial<DMGenerationOptions> = {}
  ): Promise<DMResult> {
    const config: DMGenerationOptions = {
      platform: 'twitter',
      tone: 'friendly',
      language: 'ja',
      minLength: 120,
      maxLength: 280,
      ...options
    };

    try {
      const prompt = this.buildPersonalizedPrompt(fanContext, config);
      
      const response = await this.openai.chat.completions.create({
        model: this.modelConfig.model,
        messages: [
          {
            role: 'system',
            content: this.getSystemPrompt(config)
          },
          {
            role: 'user',
            content: prompt
          }
        ],
        temperature: this.modelConfig.temperature,
        max_tokens: this.modelConfig.maxTokens
      });

      const generatedMessage = response.choices[0]?.message?.content?.trim() || '';
      
      const result: DMResult = {
        message: generatedMessage,
        length: generatedMessage.length,
        tone: config.tone,
        estimatedSentiment: this.analyzeSentiment(generatedMessage),
        generatedAt: new Date().toISOString()
      };

      return result;

    } catch (error) {
      console.error('âŒ Personalized DM generation failed:', error);
      return this.generateFallbackDM(config);
    }
  }

  // ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹ç¯‰
  private getSystemPrompt(config: DMGenerationOptions): string {
    const basePrompt = `ã‚ãªãŸã¯ã€ã‚¯ãƒªã‚¨ã‚¤ã‚¿ãƒ¼ã¨ãƒ•ã‚¡ãƒ³ã®é–¢ä¿‚ã‚’æ·±ã‚ã‚‹ã€è¦ªã—ã¿ã‚„ã™ãã¦èª å®ŸãªDMãƒ©ã‚¤ã‚¿ãƒ¼ã§ã™ã€‚

é‡è¦ãªã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ï¼š
1. ã€æ–‡å­—æ•°ã€‘: ${config.minLength}æ–‡å­—ä»¥ä¸Š${config.maxLength}æ–‡å­—ä»¥å†…ã§æ›¸ã
2. ã€ãƒˆãƒ¼ãƒ³ã€‘: ${config.tone === 'friendly' ? 'è¦ªã—ã¿ã‚„ã™ãè‡ªç„¶ãª' : config.tone === 'professional' ? 'ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«ã§ä¸å¯§ãª' : 'ã‚«ã‚¸ãƒ¥ã‚¢ãƒ«ã§è¦ªè¿‘æ„Ÿã®ã‚ã‚‹'}å£èª¿
3. ã€ç›®çš„ã€‘: ãƒ•ã‚¡ãƒ³ã¨ã®é–¢ä¿‚æ§‹ç¯‰ã¨ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆå‘ä¸Š
4. ã€ç¦æ­¢äº‹é …ã€‘: 
   - å•†å“ã®ç›´æ¥çš„ãªå®£ä¼
   - å€‹äººæƒ…å ±ã®è¦æ±‚
   - éåº¦ã«é¦´ã‚Œé¦´ã‚Œã—ã„è¡¨ç¾
   - ã‚¹ãƒ‘ãƒ ã£ã½ã„å†…å®¹

5. ã€å¿…é ˆè¦ç´ ã€‘:
   - æ„Ÿè¬ã®æ°—æŒã¡
   - ä»Šå¾Œã®é–¢ä¿‚ã¸ã®æœŸå¾…
   - è‡ªç„¶ãªè¿”ä¿¡ã‚’ä¿ƒã™è¦ç´ `;

    if (config.platform === 'twitter') {
      return basePrompt + '\n6. ã€Twitterç‰¹åŒ–ã€‘: ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°ã¯æ§ãˆã‚ã«ã€ãƒªãƒ—ãƒ©ã‚¤ã—ã‚„ã™ã„å†…å®¹ã«';
    }

    return basePrompt;
  }

  // Hello-Worldç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹ç¯‰
  private buildHelloWorldPrompt(config: DMGenerationOptions): string {
    return `${config.creatorName}ã¨ã—ã¦ã€æ–°ã—ã„ãƒ•ã‚¡ãƒ³ã«é€ã‚‹æœ€åˆã®DMãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚

ã‚·ãƒãƒ¥ã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ï¼š
- ç›¸æ‰‹ã¯æœ€è¿‘ãƒ•ã‚©ãƒ­ãƒ¼ã—ã¦ãã‚ŒãŸæ–°ã—ã„ãƒ•ã‚¡ãƒ³
- ã¾ã ç›´æ¥ã‚„ã‚Šã¨ã‚Šã—ãŸã“ã¨ã¯ãªã„
- ã‚ãªãŸã®æ´»å‹•ã«èˆˆå‘³ã‚’æŒã£ã¦ãã‚Œã¦ã„ã‚‹

ç”Ÿæˆã—ã¦ãã ã•ã„ï¼šè¦ªã—ã¿ã‚„ã™ãã€æ„Ÿè¬ã®æ°—æŒã¡ãŒä¼ã‚ã‚‹åˆå›DM
${config.minLength}æ–‡å­—ä»¥ä¸Š${config.maxLength}æ–‡å­—ä»¥å†…ã§ã€è¿”ä¿¡ã—ãŸããªã‚‹ã‚ˆã†ãªå†…å®¹ã«ã—ã¦ãã ã•ã„ã€‚`;
  }

  // ãƒ‘ãƒ¼ã‚½ãƒŠãƒ©ã‚¤ã‚ºç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹ç¯‰
  private buildPersonalizedPrompt(fanContext: string, config: DMGenerationOptions): string {
    return `ä»¥ä¸‹ã®ãƒ•ã‚¡ãƒ³æƒ…å ±ã‚’è¸ã¾ãˆã¦ã€${config.creatorName}ã¨ã—ã¦å€‹äººçš„ãªDMã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚

ãƒ•ã‚¡ãƒ³æƒ…å ±ï¼š
${fanContext}

è¦ä»¶ï¼š
- ä¸Šè¨˜ã®æƒ…å ±ã‚’è‡ªç„¶ã«ç¹”ã‚Šäº¤ãœã‚‹
- å€‹äººçš„ãªé–¢å¿ƒã‚„å…±é€šç‚¹ã‚’è¦‹ã¤ã‘ã¦è¨€åŠ
- ${config.minLength}æ–‡å­—ä»¥ä¸Š${config.maxLength}æ–‡å­—ä»¥å†…
- è¿”ä¿¡ã—ã‚„ã™ã„è³ªå•ã‚„è©±é¡Œã‚’å«ã‚ã‚‹`;
  }

  // æ„Ÿæƒ…åˆ†æï¼ˆç°¡æ˜“ç‰ˆï¼‰
  private analyzeSentiment(message: string): 'positive' | 'neutral' | 'professional' {
    const positiveWords = ['ã‚ã‚ŠãŒã¨ã†', 'å¬‰ã—ã„', 'æ¥½ã—ã„', 'ç´ æ•µ', 'ç´ æ™´ã‚‰ã—ã„', 'æ„Ÿè¬', 'å¿œæ´'];
    const professionalWords = ['ã‚ˆã‚ã—ã', 'ãŠç–²ã‚Œæ§˜', 'ã”ç¢ºèª', 'ãŠæ™‚é–“', 'ã”è³ªå•'];

    const positiveCount = positiveWords.filter(word => message.includes(word)).length;
    const professionalCount = professionalWords.filter(word => message.includes(word)).length;

    if (positiveCount > professionalCount) return 'positive';
    if (professionalCount > 0) return 'professional';
    return 'neutral';
  }

  // ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯DMç”Ÿæˆï¼ˆAPIå¤±æ•—æ™‚ï¼‰
  private generateFallbackDM(config: DMGenerationOptions): DMResult {
    const fallbackMessages = [
      `ãƒ•ã‚©ãƒ­ãƒ¼ã—ã¦ã„ãŸã ãã€ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™ï¼${config.creatorName}ã§ã™ã€‚ã„ã¤ã‚‚æŠ•ç¨¿ã‚’è¦‹ã¦ãã ã•ã£ã¦æœ¬å½“ã«å¬‰ã—ã„ã§ã™ã€‚ã“ã‚Œã‹ã‚‰ã‚‚æ¥½ã—ã„ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ãŠå±Šã‘ã§ãã‚‹ã‚ˆã†é ‘å¼µã‚Šã¾ã™ã®ã§ã€ãœã²æ„Ÿæƒ³ã‚„ã”æ„è¦‹ãªã©ã‚‚ãŠèã‹ã›ãã ã•ã„ã€‚ä»Šå¾Œã¨ã‚‚ã‚ˆã‚ã—ããŠé¡˜ã„ã—ã¾ã™ï¼`,
      
      `${config.creatorName}ã§ã™ï¼æ–°ã—ããƒ•ã‚©ãƒ­ãƒ¼ã—ã¦ãã ã•ã£ã¦ã€æœ¬å½“ã«ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™ã€‚ã‚ãªãŸã®ã‚ˆã†ãªå¿œæ´ã—ã¦ãã ã•ã‚‹æ–¹ãŒã„ã‚‹ãŠã‹ã’ã§ã€æ¯æ—¥æ¥½ã—ãæ´»å‹•ã‚’ç¶šã‘ã‚‹ã“ã¨ãŒã§ãã¦ã„ã¾ã™ã€‚ã‚‚ã—ã‚ˆã‚ã—ã‘ã‚Œã°ã€æ™®æ®µã©ã‚“ãªã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŒãŠå¥½ãã‹æ•™ãˆã¦ã„ãŸã ã‘ã‚‹ã¨å¬‰ã—ã„ã§ã™ã€‚ã“ã‚Œã‹ã‚‰ã‚‚ã‚ˆã‚ã—ããŠé¡˜ã„ã—ã¾ã™ï¼`,
      
      `ã“ã‚“ã«ã¡ã¯ï¼ãƒ•ã‚©ãƒ­ãƒ¼ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™ã€‚${config.creatorName}ã¨ã—ã¦æ´»å‹•ã—ã¦ã„ã‚‹è€…ã§ã™ã€‚ã‚ãªãŸãŒç§ã®æŠ•ç¨¿ã«èˆˆå‘³ã‚’æŒã£ã¦ãã ã•ã£ãŸã“ã¨ã€ã¨ã¦ã‚‚å…‰æ „ã«æ€ã„ã¾ã™ã€‚ä»Šå¾Œã‚‚çš†ã•ã‚“ã«å–œã‚“ã§ã„ãŸã ã‘ã‚‹ã‚ˆã†ãªå†…å®¹ã‚’å¿ƒãŒã‘ã¦ã„ãã¾ã™ã®ã§ã€ãœã²ãŠæ°—è»½ã«ã‚³ãƒ¡ãƒ³ãƒˆã‚„ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ãŠé€ã‚Šãã ã•ã„ã€‚ãŠè©±ã—ã§ãã‚‹ã®ã‚’æ¥½ã—ã¿ã«ã—ã¦ã„ã¾ã™ï¼`
    ];

    const randomMessage = fallbackMessages[Math.floor(Math.random() * fallbackMessages.length)];

    return {
      message: randomMessage,
      length: randomMessage.length,
      tone: config.tone,
      estimatedSentiment: 'positive',
      generatedAt: new Date().toISOString()
    };
  }

  // ãƒ¢ãƒ‡ãƒ«è¨­å®šæ›´æ–°ï¼ˆTrial/Proåˆ‡ã‚Šæ›¿ãˆç”¨ï¼‰
  updateModelConfig(model: 'gpt-4o-mini' | 'gpt-4o', temperature: number = 0.7): void {
    this.modelConfig = {
      model,
      temperature,
      maxTokens: model === 'gpt-4o' ? 200 : 150
    };
    console.log(`ğŸ”„ Model updated to: ${model}`);
  }

  async initialize(apiKey: string): Promise<void> {
    try {
      this.openai = new OpenAI({
        apiKey,
        dangerouslyAllowBrowser: true
      });
      console.log('âœ… OpenAI client initialized for high-speed DM generation');
    } catch (error) {
      console.error('âŒ OpenAI initialization failed:', error);
      throw error;
    }
  }

  // @mvp_checklist.md p50 < 0.5s: é«˜é€ŸDMç”Ÿæˆ
  async generateDM(request: DMRequest): Promise<DMResponse> {
    const startTime = Date.now();
    
    try {
      // ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒã‚§ãƒƒã‚¯ï¼ˆé«˜é€ŸåŒ–ï¼‰
      const cacheKey = this.generateCacheKey(request);
      const cached = this.getFromCache(cacheKey);
      
      if (cached) {
        const latency = Date.now() - startTime;
        this.recordLatency(latency);
        
        return {
          ...cached,
          generationTimeMs: latency,
          cached: true
        };
      }

      if (!this.openai) {
        throw new Error('OpenAI not initialized');
      }

      // @mvp_checklist.md Cost Guardrail: 4o-miniä½¿ç”¨
      const response = await this.openai.chat.completions.create({
        model: 'gpt-4o-mini',
        messages: [
          {
            role: 'system',
            content: this.generateSystemPrompt(request)
          },
          {
            role: 'user',
            content: this.generateUserPrompt(request)
          }
        ],
        max_tokens: 150,
        temperature: 0.7,
        top_p: 0.9,
        // ãƒ¬ã‚¹ãƒãƒ³ã‚¹é€Ÿåº¦æœ€é©åŒ–
        stream: false,
        presence_penalty: 0.1,
        frequency_penalty: 0.1
      });

      const generatedMessage = response.choices[0]?.message?.content?.trim();
      
      if (!generatedMessage) {
        throw new Error('Empty response from OpenAI');
      }

      const dmResponse: DMResponse = {
        message: generatedMessage,
        length: generatedMessage.length,
        sentiment: this.analyzeSentiment(generatedMessage),
        generationTimeMs: Date.now() - startTime,
        cached: false,
        model: 'gpt-4o-mini'
      };

      // ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜
      this.saveToCache(cacheKey, dmResponse);

      // ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·è¨˜éŒ²
      this.recordLatency(dmResponse.generationTimeMs);

      // p50 > 0.6s ã®å ´åˆã¯Slack Alert
      const metrics = this.getLatencyMetrics();
      if (metrics.p50 > 600) {
        chrome.runtime.sendMessage({
          type: 'SEND_SLACK_ALERT',
          message: `ğŸŒ High latency detected: p50=${metrics.p50.toFixed(0)}ms, p95=${metrics.p95.toFixed(0)}ms`,
          channel: '#performance-alerts'
        });
      }

      // GA4ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹é€ä¿¡
      chrome.runtime.sendMessage({
        type: 'SEND_GA4_EVENT',
        eventName: 'dm_generated',
        parameters: {
          generation_time_ms: dmResponse.generationTimeMs,
          message_length: dmResponse.length,
          sentiment: dmResponse.sentiment,
          cached: dmResponse.cached,
          target_met: dmResponse.generationTimeMs <= this.TARGET_LATENCY
        }
      });

      return dmResponse;

    } catch (error) {
      const errorLatency = Date.now() - startTime;
      console.error('âŒ DM generation failed:', error);
      
      // ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: äº‹å‰å®šç¾©ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
      const fallbackMessage = this.getFallbackMessage(request);
      
      chrome.runtime.sendMessage({
        type: 'SEND_GA4_EVENT',
        eventName: 'dm_generation_error',
        parameters: {
          error_message: error.message,
          fallback_used: true,
          error_latency_ms: errorLatency
        }
      });

      return {
        message: fallbackMessage,
        length: fallbackMessage.length,
        sentiment: 'neutral',
        generationTimeMs: errorLatency,
        cached: false,
        model: 'fallback'
      };
    }
  }

  // @mvp_checklist.md p50/p95ç›£è¦–
  getLatencyMetrics(): LatencyMetrics {
    if (this.latencyHistory.length === 0) {
      return {
        p50: 0,
        p95: 0,
        p99: 0,
        average: 0,
        count: 0,
        lastUpdated: Date.now()
      };
    }

    const sorted = [...this.latencyHistory].sort((a, b) => a - b);
    const count = sorted.length;

    return {
      p50: sorted[Math.floor(count * 0.5)] || 0,
      p95: sorted[Math.floor(count * 0.95)] || 0,
      p99: sorted[Math.floor(count * 0.99)] || 0,
      average: sorted.reduce((sum, val) => sum + val, 0) / count,
      count,
      lastUpdated: Date.now()
    };
  }

  private recordLatency(latencyMs: number): void {
    this.latencyHistory.push(latencyMs);
    
    // å±¥æ­´ã‚µã‚¤ã‚ºåˆ¶é™
    if (this.latencyHistory.length > this.MAX_HISTORY) {
      this.latencyHistory = this.latencyHistory.slice(-this.MAX_HISTORY);
    }
  }

  private generateCacheKey(request: DMRequest): string {
    return btoa(JSON.stringify({
      targetUser: request.targetUser,
      tone: request.tone || 'friendly',
      language: request.language || 'ja'
    }));
  }

  private getFromCache(key: string): DMResponse | null {
    const cached = this.cache.get(key);
    if (!cached) return null;

    const isExpired = Date.now() - cached.timestamp > this.CACHE_TTL;
    if (isExpired) {
      this.cache.delete(key);
      return null;
    }

    return cached.response;
  }

  private saveToCache(key: string, response: DMResponse): void {
    this.cache.set(key, {
      response,
      timestamp: Date.now()
    });

    // ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚µã‚¤ã‚ºåˆ¶é™
    if (this.cache.size > 100) {
      const oldestKey = this.cache.keys().next().value;
      this.cache.delete(oldestKey);
    }
  }

  private generateSystemPrompt(request: DMRequest): string {
    const language = request.language || 'ja';
    
    if (language === 'ja') {
      return `ã‚ãªãŸã¯ã‚¯ãƒªã‚¨ã‚¤ã‚¿ãƒ¼å‘ã‘ã®DMè‡ªå‹•åŒ–ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚ä»¥ä¸‹ã®è¦ä»¶ã§ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ï¼š

è¦ä»¶ï¼š
- 120æ–‡å­—ä»¥ä¸Šã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
- ${request.tone || 'friendly'}ãªãƒˆãƒ¼ãƒ³
- è‡ªç„¶ã§äººé–“ã‚‰ã—ã„è¡¨ç¾
- ç›¸æ‰‹ã‚’å°Šé‡ã—ã€ä¾¡å€¤ã‚’æä¾›ã™ã‚‹å†…å®¹
- ã‚¹ãƒ‘ãƒ ã‚„å–¶æ¥­æ„Ÿã‚’é¿ã‘ã‚‹
- è¿”ä¿¡ã‚’ä¿ƒã™è³ªå•ã‚„ææ¡ˆã‚’å«ã‚ã‚‹

é‡è¦ï¼šé€Ÿåº¦å„ªå…ˆã§ã€ç°¡æ½”ã‹ã¤åŠ¹æœçš„ãªãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚`;
    } else {
      return `You are a DM automation assistant for creators. Generate messages with these requirements:

Requirements:
- 120+ characters minimum
- ${request.tone || 'friendly'} tone
- Natural, human-like expression
- Respectful and value-providing content
- Avoid spam or overly sales-like language
- Include questions or suggestions that encourage replies

Important: Prioritize speed while creating concise and effective messages.`;
    }
  }

  private generateUserPrompt(request: DMRequest): string {
    const language = request.language || 'ja';
    
    if (language === 'ja') {
      return `ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒ¦ãƒ¼ã‚¶ãƒ¼: ${request.targetUser}
${request.context ? `ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ: ${request.context}` : ''}

ã“ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«é€ä¿¡ã™ã‚‹é­…åŠ›çš„ãªDMã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚`;
    } else {
      return `Target user: ${request.targetUser}
${request.context ? `Context: ${request.context}` : ''}

Generate an engaging DM for this user.`;
    }
  }

  private getFallbackMessage(request: DMRequest): string {
    const language = request.language || 'ja';
    
    const fallbacks = {
      ja: [
        `${request.targetUser}ã•ã‚“ã€ãŠç–²ã‚Œæ§˜ã§ã™ï¼ã‚ãªãŸã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ã„ã¤ã‚‚æ‹è¦‹ã•ã›ã¦ã„ãŸã ã„ã¦ãŠã‚Šã€ã¨ã¦ã‚‚å‹‰å¼·ã«ãªã£ã¦ã„ã¾ã™ã€‚ã‚‚ã—ã‚ˆã‚ã—ã‘ã‚Œã°ã€ä»Šåº¦ã‚³ãƒ©ãƒœãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã«ã¤ã„ã¦ãŠè©±ã—ã§ãã‚Œã°ã¨æ€ã„ã¾ã™ã€‚ãŠå¿™ã—ã„ä¸­æç¸®ã§ã™ãŒã€ã”æ¤œè¨ã„ãŸã ã‘ã¾ã™ã§ã—ã‚‡ã†ã‹ï¼Ÿ`,
        `${request.targetUser}ã•ã‚“ã€ã“ã‚“ã«ã¡ã¯ï¼ã‚ãªãŸã®æœ€æ–°ã®æŠ•ç¨¿ã‚’è¦‹ã¦ã€ã™ãã«ã‚³ãƒ¡ãƒ³ãƒˆã—ãŸããªã‚Šã¾ã—ãŸã€‚ç´ æ™´ã‚‰ã—ã„ã‚¯ã‚ªãƒªãƒ†ã‚£ã§ã™ã­ï¼ã‚‚ã—ãŠæ™‚é–“ãŒã‚ã‚‹ã¨ãã«ã€ã‚¯ãƒªã‚¨ã‚¤ã‚¿ãƒ¼åŒå£«ã®æƒ…å ±äº¤æ›ã‚’ã•ã›ã¦ã„ãŸã ã‘ã‚Œã°å¬‰ã—ã„ã§ã™ã€‚ã‚ˆã‚ã—ããŠé¡˜ã„ã—ã¾ã™ï¼`
      ],
      en: [
        `Hi ${request.targetUser}! I've been following your content and find it really inspiring. Would love to connect and potentially explore some collaboration opportunities. Let me know if you'd be interested in chatting!`,
        `Hello ${request.targetUser}! Your recent posts caught my attention - amazing work! I'd love to connect with fellow creators and exchange ideas. Hope to hear from you soon!`
      ]
    };

    const messages = fallbacks[language] || fallbacks.ja;
    return messages[Math.floor(Math.random() * messages.length)];
  }

  // ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢ï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰
  clearCache(): void {
    this.cache.clear();
    console.log('âœ… DM generation cache cleared');
  }

  // ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·å±¥æ­´ã‚¯ãƒªã‚¢ï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰
  clearLatencyHistory(): void {
    this.latencyHistory = [];
    console.log('âœ… Latency history cleared');
  }
}

// Week-1ç”¨ã®DMã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ãƒ¼ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
export const dmGenerator = new DMGenerator();

// ãƒ‡ãƒ¢ç”¨ã®ç°¡æ˜“ç”Ÿæˆé–¢æ•°
export const generateQuickDM = async (fanName?: string): Promise<string> => {
  try {
    const result = await dmGenerator.generateHelloWorldDM({
      fanName,
      minLength: 120,
      maxLength: 200
    });
    return result.message;
  } catch (error) {
    console.error('Quick DM generation failed:', error);
    return 'ãƒ•ã‚©ãƒ­ãƒ¼ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™ï¼ãŠè©±ã—ã§ãã¦å¬‰ã—ã„ã§ã™ã€‚ã“ã‚Œã‹ã‚‰ã‚‚ã‚ˆã‚ã—ããŠé¡˜ã„ã—ã¾ã™ï¼';
  }
}; 